# app.py

import os
import json
import uuid
import argparse
from io import BytesIO
from pathlib import Path

import boto3
import numpy as np
import faiss    # pip install faiss-cpu
import cv2
from PIL import Image, ImageOps, ImageFile, ImageFilter

from flask import Flask, request, jsonify
from flask_cors import CORS

from sqlalchemy import create_engine, Column, Integer, String
from sqlalchemy.orm import sessionmaker, declarative_base

# â”€â”€ å…±é€šè¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# DB
DATABASE_URL = os.environ.get(
    "DATABASE_URL",
    "sqlite:///./local_dev.db"
)
engine  = create_engine(DATABASE_URL)
Session = sessionmaker(bind=engine)
Base    = declarative_base()

class ProductMapping(Base):
    __tablename__ = "products"
    id     = Column(Integer, primary_key=True)
    name   = Column(String)
    s3_key = Column(String)

# S3 ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
ImageFile.LOAD_TRUNCATED_IMAGES = True
S3_BUCKET = os.environ.get("S3_BUCKET", "registered_images")
s3        = boto3.client("s3")

# Flask
app = Flask(__name__)
CORS(app)
app.logger.setLevel("INFO")

# âœ… ã“ã“ã«è¿½è¨˜ï¼ˆãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆï¼‰
Base.metadata.create_all(bind=engine)

# ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç½®ãå ´
CACHE_DIR  = "cache"
INDEX_PATH = os.path.join(CACHE_DIR, "faiss.index")
KEYS_PATH  = os.path.join(CACHE_DIR, "keys.json")

# â”€â”€ å‰å‡¦ç†ãƒ˜ãƒ«ãƒ‘ãƒ¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def crop_to_object(pil_img, thresh=200):
    arr  = np.array(pil_img.convert("RGB"))
    gray = cv2.cvtColor(arr, cv2.COLOR_RGB2GRAY)
    _, binimg = cv2.threshold(gray, thresh, 255, cv2.THRESH_BINARY_INV)
    cnts, _  = cv2.findContours(binimg, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if not cnts:
        return pil_img
    x, y, w, h = cv2.boundingRect(max(cnts, key=cv2.contourArea))
    return pil_img.crop((x, y, x+w, y+h))

def preprocess_pil(img, size=100):
    img = img.convert("L")
    img = ImageOps.exif_transpose(img)
    img = img.filter(ImageFilter.MedianFilter(3))
    img = img.filter(ImageFilter.GaussianBlur(radius=1))
    img = ImageOps.fit(img, (size, size))
    return ImageOps.autocontrast(img, cutoff=1)

# â”€â”€ ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ§‹ç¯‰æ©Ÿèƒ½ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def build_cache(cache_dir=CACHE_DIR, index_path=INDEX_PATH, dim=256):
    os.makedirs(cache_dir, exist_ok=True)

    # 1) DB ã«ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹ s3_key ã®ã¿å–å¾—
    session = Session()
    keys = [pm.s3_key for pm in session.query(ProductMapping).all()]
    session.close()

    descriptors = []

    # 2) å„ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ â†’ ORB â†’ å›ºå®šé•·ãƒ™ã‚¯ãƒˆãƒ«
    orb = cv2.ORB_create()
    for key in keys:
        resp = s3.get_object(Bucket=S3_BUCKET, Key=key)
        img  = Image.open(BytesIO(resp["Body"].read()))
        gray = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2GRAY)
        _, des = orb.detectAndCompute(gray, None)
        vec = np.zeros(dim, dtype="float32")
        if des is not None:
            flat = des.flatten()
            vec[: min(dim, flat.shape[0])] = flat[:dim]
        else:
            app.logger.warning(f"âŒ ç‰¹å¾´é‡ãŒå–ã‚Œã¾ã›ã‚“ã§ã—ãŸ: {key}")
            continue  # ã‚¹ã‚­ãƒƒãƒ—ï¼    
        descriptors.append(vec)
        np.save(os.path.join(cache_dir, f"{key}.npy"), vec)
     
    # âœ… ã“ã“ã«è¿½åŠ ï¼ˆnp.stack() ã®å‰ï¼‰
    if not descriptors:
        app.logger.error("ğŸš« æœ‰åŠ¹ãªç‰¹å¾´é‡ãŒæŠ½å‡ºã•ã‚ŒãŸç”»åƒãŒ 0 ä»¶ã§ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä½œæˆä¸­æ­¢")
        return

    xb    = np.stack(descriptors)


    # 3) keys.json ã‚’ä¿å­˜
    with open(KEYS_PATH, "w", encoding="utf-8") as f:
        json.dump(keys, f, ensure_ascii=False, indent=2)

    # 4) Faiss ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰ï¼‹ä¿å­˜
    xb    = np.stack(descriptors)
    index = faiss.IndexFlatL2(dim)
    index.add(xb)
    faiss.write_index(index, index_path)

    app.logger.info(f"âœ… ã‚­ãƒ£ãƒƒã‚·ãƒ¥({len(keys)}ä»¶) & ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ç”Ÿæˆã—ã¾ã—ãŸ â†’ {cache_dir}/ , {index_path}")

# â”€â”€ ç”»åƒç™»éŒ²ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@app.route("/register_image", methods=["POST"])
def register_image():
    name = request.form.get("name")
    if not name:
        return "invalid request (no name)", 400

    if "image" in request.files:
        stream = request.files["image"].stream
    elif "image_url" in request.form:
        import requests
        try:
            r = requests.get(request.form["image_url"])
            r.raise_for_status()
            stream = BytesIO(r.content)
        except Exception as e:
            app.logger.error(f"Failed download image_url: {e}")
            return "invalid image_url", 400
    else:
        return "invalid request (no image or image_url)", 400

    try:
        img = Image.open(stream)
        img = ImageOps.exif_transpose(img).convert("RGB")
        img.thumbnail((640, 640), Image.Resampling.LANCZOS)
        filename = f"{uuid.uuid4().hex}.jpg"
        path = os.path.join("registered_images", filename)
        os.makedirs("registered_images", exist_ok=True)
        img.save(path, format="JPEG", quality=80, optimize=True)

        s3.upload_file(path, S3_BUCKET, filename, ExtraArgs={"ContentType":"image/jpeg"})
        app.logger.info(f"â˜ï¸ uploaded to S3://{S3_BUCKET}/{filename}")
        return "OK", 200
    except Exception as e:
        app.logger.exception(e)
        return "error", 500

# â”€â”€ ç”»åƒèªè­˜ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å¤‰æ›´ç‚¹è¦ç´„ï¼š
# 1. SIFTã®sigmaã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆ1.6ï¼‰ã«æˆ»ã™
# 2. ç‰¹å¾´é‡ã‚’L2æ­£è¦åŒ–
# 3. ã‚¹ã‚³ã‚¢è¨ˆç®—ã‚’ log or 1/(1+dist) ã«å¤‰æ›´ï¼ˆåˆ†ã‹ã‚Šã‚„ã™ã•é‡è¦–ï¼‰
# 4. JSONé‡è¤‡appendå‰Šé™¤
#
# ğŸ” ä¿®æ­£å¯¾è±¡ï¼špredict()

@app.route("/predict", methods=["POST"])
def predict():
    try:
        # 1) ç”»åƒå–å¾—
        if "image" in request.files:
            raw = Image.open(request.files["image"].stream)
        elif "image_url" in request.form:
            import requests
            r = requests.get(request.form["image_url"])
            r.raise_for_status()
            raw = Image.open(BytesIO(r.content))
        else:
            return jsonify(error="ç”»åƒãŒã‚ã‚Šã¾ã›ã‚“"), 400

        # 2) ç‰¹å¾´é‡æŠ½å‡ºï¼ˆSIFT, L2æ­£è¦åŒ–ï¼‰
        gray = cv2.cvtColor(np.array(raw.convert("RGB")), cv2.COLOR_RGB2GRAY)
        sift = cv2.SIFT_create(sigma=1.6)
        _, des = sift.detectAndCompute(gray, None)

        q_arr = np.zeros(256, dtype="float32")
        if des is not None:
            flat = des.flatten()
            vec = flat[:256]
            if np.linalg.norm(vec) != 0:
                vec = vec / np.linalg.norm(vec)  # L2 normalize
            q_arr[: len(vec)] = vec
        else:
            app.logger.warning("âŒ ã‚¯ã‚¨ãƒªç”»åƒã®ç‰¹å¾´é‡ãŒæŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
            return jsonify(error="ç”»åƒãŒä¸æ˜ç­ã§ã™"), 400

        # 3) ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ã‚­ãƒ¼èª­ã¿è¾¼ã¿
        index = faiss.read_index(INDEX_PATH)
        with open(KEYS_PATH, "r", encoding="utf-8") as f:
            keys = json.load(f)

        # 4) æ¤œç´¢
        k = len(keys)
        D, I = index.search(np.expand_dims(q_arr, 0), k=k)

        # 5) çµæœæ•´å½¢ï¼ˆé‡è¤‡åé™¤å¤–ï¼‰
        session = Session()
        seen_names = set()
        all_scores = []
        for dist, idx in zip(D[0], I[0]):
            key = keys[idx]
            prod = session.query(ProductMapping).filter_by(s3_key=key).first()
            name = prod.name if prod else key.rsplit(".", 1)[0]
            if name in seen_names:
                continue
            seen_names.add(name)

            # ğŸ’¡ ã‚¹ã‚³ã‚¢è¨ˆç®—æ–¹æ³•ï¼ˆã‚ã‹ã‚Šã‚„ã™ãï¼‰
            score = 1 / (1 + dist)
            app.logger.info(f"ğŸ“Š dist={dist:.2f}, score={score:.4f}, name={name}")

            all_scores.append({
                "name": name,
                "score": round(score, 4)
            })
        session.close()

        return jsonify(all_similarity_scores=all_scores_serializable), 200
        
    except Exception as e:
        app.logger.exception(e)
        return jsonify(error="å‡¦ç†ã‚¨ãƒ©ãƒ¼"), 500




# â”€â”€ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«èª­ã¿è¾¼ã¿æ™‚ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if not Path(INDEX_PATH).exists() or not Path(KEYS_PATH).exists():
    app.logger.info("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã®ã§è‡ªå‹•ç”Ÿæˆã—ã¾ã™ (ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«èª­ã¿è¾¼ã¿æ™‚)")
    build_cache(dim=256)

# â”€â”€ ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--build-cache", action="store_true",
        help="S3 ã‹ã‚‰ç‰¹å¾´é‡ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼†Faissã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆ"
    )
    args = parser.parse_args()

    if args.build_cache:
        build_cache()
    else:
        port = int(os.environ.get("PORT", 10000))
        app.run(host="0.0.0.0", port=port, debug=False)

if __name__ == "__main__":
    main()