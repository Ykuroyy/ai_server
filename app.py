# app.py
import os, json, uuid, argparse
from io import BytesIO
from pathlib import Path
from datetime import datetime
import numpy as np
import cv2
import faiss
import boto3
import requests

from PIL import Image, ImageOps, ImageFile
from flask import Flask, request, jsonify
from flask_cors import CORS
from sqlalchemy import create_engine, Column, Integer, String, DateTime
from sqlalchemy.orm import sessionmaker, declarative_base

# --- å…±é€šè¨­å®š ---
ImageFile.LOAD_TRUNCATED_IMAGES = True
DATABASE_URL = os.environ.get("DATABASE_URL", "sqlite:///./local_dev.db")
S3_BUCKET    = os.environ.get("S3_BUCKET", "registered_images")

engine  = create_engine(DATABASE_URL)
Session = sessionmaker(bind=engine)
Base    = declarative_base()
s3      = boto3.client(
    's3',
    region_name=os.getenv("AWS_REGION"),
    aws_access_key_id=os.getenv("AWS_ACCESS_KEY_ID"),
    aws_secret_access_key=os.getenv("AWS_SECRET_ACCESS_KEY")
)

CACHE_DIR  = "cache"
INDEX_PATH = os.path.join(CACHE_DIR, "faiss.index")
KEYS_PATH  = os.path.join(CACHE_DIR, "keys.json")

class ProductMapping(Base):
    __tablename__ = "products"
    id     = Column(Integer, primary_key=True)
    name   = Column(String)
    s3_key = Column(String)
    created_at = Column(DateTime)
    updated_at = Column(DateTime)

# --- Flask åˆæœŸåŒ– ---
app = Flask(__name__)
CORS(app)
Base.metadata.create_all(bind=engine)

# --- v2: Railsã‹ã‚‰ç”»åƒURLã‚’å—ã‘å–ã‚ŠS3ã«ä¿å­˜ï¼‹DBç™»éŒ² ---
@app.route("/register_image_v2", methods=["POST"])
def register_image_v2():
    try:
        data = request.get_json()
        image_url = data["image_url"]
        product_name = data["name"]

        response = requests.get(image_url)
        if response.status_code != 200:
            return jsonify({"error": "ç”»åƒå–å¾—å¤±æ•—"}), 400

        # é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼ˆã™ã§ã«åŒã˜å•†å“åãŒç™»éŒ²ã•ã‚Œã¦ã„ãŸã‚‰ç™»éŒ²ã‚¹ã‚­ãƒƒãƒ—ï¼‰
        session = Session()
        existing = session.query(ProductMapping).filter_by(name=product_name).first()
        if existing:
            session.close()
            return jsonify({"message": "æ—¢ã«ç™»éŒ²æ¸ˆã¿", "filename": existing.s3_key}), 200

        filename = f"{product_name}_{os.urandom(4).hex()}.jpg"
        s3_key = f"registered_images/{filename}"
        s3.upload_fileobj(BytesIO(response.content), S3_BUCKET, s3_key)

        new_product = ProductMapping(
            name=product_name,
            s3_key=s3_key,
            created_at=datetime.utcnow(),
            updated_at=datetime.utcnow()
        )
        session.add(new_product)
        session.commit()
        session.close()

        app.logger.info(f"âœ… ç”»åƒä¿å­˜æˆåŠŸ: {filename}")
        return jsonify({"message": "ä¿å­˜å®Œäº†", "filename": filename}), 200

    except Exception as e:
        app.logger.error(f"âŒ register_image_v2 ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return jsonify({"error": "ç™»éŒ²ã‚¨ãƒ©ãƒ¼", "detail": str(e)}), 500


# --- æ‰‹å‹•ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç™»éŒ²ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ ---
@app.route("/register_image", methods=["POST"])
def register_image():
    name = request.form.get("name")
    if not name:
        return "no name", 400

    if "image" not in request.files:
        return "no image", 400

    try:
        img = Image.open(request.files["image"].stream).convert("RGB")
        img = ImageOps.exif_transpose(img)
        img.thumbnail((640, 640))
        filename = f"{uuid.uuid4().hex}.jpg"
        local_path = os.path.join("registered_images", filename)
        os.makedirs("registered_images", exist_ok=True)
        img.save(local_path, format="JPEG", quality=80)

        s3.upload_file(local_path, S3_BUCKET, filename, ExtraArgs={"ContentType": "image/jpeg"})
        session = Session()
        new_product = ProductMapping(
            name=name,
            s3_key=filename,
            created_at=datetime.utcnow(),
            updated_at=datetime.utcnow()
        )
        session.add(new_product)
        session.commit()
        session.close()

        return "OK", 200
    except Exception as e:
        app.logger.exception("ç™»éŒ²å¤±æ•—")
        return str(e), 500

# --- ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ§‹ç¯‰ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ ---
@app.route("/build_cache", methods=["POST"])
def trigger_build_cache():
    try:
        build_cache(dim=256)
        return jsonify({"status": "ok"}), 200
    except Exception as e:
        app.logger.exception("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä½œæˆå¤±æ•—")
        return jsonify({"error": str(e)}), 500

# --- ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä½œæˆå‡¦ç† ---
def build_cache(cache_dir=CACHE_DIR, index_path=INDEX_PATH, dim=256):
    os.makedirs(cache_dir, exist_ok=True)
    session = Session()
    keys = [p.s3_key for p in session.query(ProductMapping).all()]
    session.close()

    descriptors = []
    for key in keys:
        resp = s3.get_object(Bucket=S3_BUCKET, Key=key)
        img  = Image.open(BytesIO(resp["Body"].read()))
        gray = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2GRAY)
        sift = cv2.SIFT_create()
        _, des = sift.detectAndCompute(gray, None)

        vec = np.zeros(dim, dtype="float32")
        if des is not None:
            flat = des.flatten()
            vec[:min(dim, len(flat))] = flat[:dim]
            descriptors.append(vec)
        else:
            app.logger.warning(f"âŒ ç‰¹å¾´é‡æŠ½å‡ºå¤±æ•—: {key}")

    if not descriptors:
        raise RuntimeError("ğŸš« ç‰¹å¾´é‡ã‚¼ãƒ­ä»¶ã€‚ç™»éŒ²ç”»åƒã‚’ç¢ºèªã—ã¦ãã ã•ã„")

    xb = np.stack(descriptors)
    index = faiss.IndexFlatL2(dim)
    index.add(xb)
    faiss.write_index(index, index_path)
    with open(KEYS_PATH, "w", encoding="utf-8") as f:
        json.dump(keys, f)

    app.logger.info(f"âœ… ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç”Ÿæˆ: {len(keys)}ä»¶")

# --- ç”»åƒèªè­˜ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ ---
@app.route("/predict", methods=["POST"])
def predict():
    if not os.path.exists(INDEX_PATH):
        return jsonify({"error": "ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœªæ§‹ç¯‰ã§ã™"}), 500

    if "image" not in request.files:
        return jsonify({"error": "ç”»åƒãŒã‚ã‚Šã¾ã›ã‚“"}), 400

    raw = Image.open(request.files["image"].stream).convert("RGB")
    gray = cv2.cvtColor(np.array(raw), cv2.COLOR_RGB2GRAY)
    sift = cv2.SIFT_create()
    _, des = sift.detectAndCompute(gray, None)

    if des is None:
        return jsonify({"error": "ç”»åƒã®ç‰¹å¾´é‡ãŒæŠ½å‡ºã§ãã¾ã›ã‚“"}), 400

    vec = des.flatten()[:256]
    if np.linalg.norm(vec) != 0:
        vec = vec / np.linalg.norm(vec)

    q_arr = np.zeros(256, dtype="float32")
    q_arr[:len(vec)] = vec

    index = faiss.read_index(INDEX_PATH)
    with open(KEYS_PATH, encoding="utf-8") as f:
        keys = json.load(f)

    k = len(keys)
    D, I = index.search(np.expand_dims(q_arr, 0), k=k)

    app.logger.info(f"ğŸ” æ¤œç´¢çµæœ: I={I[0]}, D={D[0]}")
    app.logger.info(f"ğŸ” ç™»éŒ²ã‚­ãƒ¼æ•°: {len(keys)}")

    session = Session()
    results = []
    seen = set()
    for dist, idx in zip(D[0], I[0]):
        if idx < 0 or idx >= len(keys):  # â† ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç¯„å›²ãƒã‚§ãƒƒã‚¯
            app.logger.warning(f"âš ï¸ ç„¡åŠ¹ãªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: idx={idx}, è·³ã°ã—ã¾ã™")
            continue

        key = keys[idx]
        prod = session.query(ProductMapping).filter_by(s3_key=key).first()
        name = prod.name if prod else key.rsplit(".", 1)[0]
        if name in seen:
            continue
        seen.add(name)
        score = max(0.0, 1 - dist / 10000000)
        results.append({"name": name, "score": round(score, 4)})

    session.close()

    return jsonify(all_similarity_scores=results), 200





# --- ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ ---
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--build-cache", action="store_true")
    args = parser.parse_args()

    if args.build_cache:
        build_cache()
    else:
        if not Path(INDEX_PATH).exists():
            app.logger.info("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒç„¡ã„ã®ã§è‡ªå‹•ä½œæˆ")
            build_cache(dim=256)
        app.run(host="0.0.0.0", port=int(os.environ.get("PORT", 10000)))

if __name__ == "__main__":
    main()
